---
title: Points, Vectors, and Payloads
weight: 1
---

{{< date >}} Day 1 {{< /date >}}

# Points, Vectors, and Payloads

Understanding Qdrant's core data model is essential for building effective vector search applications. This video establishes the precise technical vocabulary and concepts you'll use throughout the course.

{{< youtube "YOUR_YOUTUBE_VIDEO_ID_HERE" >}}


## Points: The Core Entity

**Points** are the central entity that Qdrant operates with. A point is a record consisting of:

- **Unique ID** (64-bit unsigned integer or UUID)
- **Vector** (dense, sparse, or multivector)
- **Optional Payload** (metadata)

If IDs are not provided, Qdrant Client will automatically generate them as random UUIDs.

## Vector Types in Qdrant

Qdrant supports different types of vectors to provide various approaches to data exploration and search.

### Dense Vectors

Dense vectors are the typical vector representation used in vector search, generated by the majority of embedding models.

At the core of every vector is a set of numbers that together form a representation of the data in a multi-dimensional space. Dense vectors capture essential patterns or relationships within the data - that's why the term "embedding" is often used interchangeably with "vector" when referring to the output of these models.

**Key Characteristics:**
- Generated by neural networks to capture complex relationships and semantics
- Represented as vectors in high-dimensional space
- For textual data, embeddings encapsulate language nuances like semantics and context
- Similar sentences produce similar embeddings due to shared linguistic elements

The beauty of embeddings lies in distilling data complexity into something comparable across multi-dimensional space.

### Sparse Vectors

Mathematically identical to dense vectors, but containing many zeros. They use optimized storage representation and have a different shape than dense vectors.

**Representation:**
Sparse vectors are represented as a list of (index, value) pairs:
- **index**: integer position of non-zero value
- **value**: floating point number

**Example:**
```python
# Dense vector: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0]
# Sparse representation: [(6, 1.0), (7, 2.0)]

# Qdrant JSON format:
{
 "indices": [6, 7],
 "values": [1.0, 2.0]
}
```

**Implementation:**
```python
client.upsert(
   collection_name="{collection_name}",
   points=[
       models.PointStruct(
           id=1,
           vector={
               "text": models.SparseVector(
                   indices=[6, 7],
                   values=[1.0, 2.0],
               )
           },
       ),
       models.PointStruct(
           id=2,
           vector={
               "text": models.SparseVector(
                   indices=[1, 2, 3, 4, 5],
                   values=[0.1, 0.2, 0.3, 0.4, 0.5],
               )
           },
       ),
   ],
)
```

### Multivectors

Qdrant supports storing a variable number of same-shaped dense vectors in a single point - essentially a matrix of dense vectors.

**Structure:**
- Fixed matrix length per collection
- Variable number of vectors per point
- All vectors in the matrix have the same shape

**Example:**
```python
"vector": [
   [-0.013,  0.020, -0.007, -0.111],
   [-0.030, -0.055,  0.001,  0.072],
   [-0.041,  0.014, -0.032, -0.062],
   # ...
]
```

**Use Cases:**
- Multiple embeddings for the same object from different angles
- ColBERT-style models that output vectors for each token
- Any scenario requiring multiple related vectors per data point

### Named Vectors

You can attach multiple vector types to a single point using **Named Vectors** - separate vector spaces within the same collection.

**Collection Creation:**
```python
from qdrant_client import QdrantClient, models

client = QdrantClient(url="http://localhost:6333")

client.create_collection(
   collection_name="{collection_name}",
   vectors_config={
       "image": models.VectorParams(size=4, distance=models.Distance.DOT),
       "text": models.VectorParams(size=5, distance=models.Distance.COSINE),
   },
   sparse_vectors_config={"text-sparse": models.SparseVectorParams()},
)
```

**Point Insertion:**
```python
client.upsert(
   collection_name="{collection_name}",
   points=[
       models.PointStruct(
           id=1,
           vector={
               "image": [0.9, 0.1, 0.1, 0.2],
               "text": [0.4, 0.7, 0.1, 0.8, 0.1, 0.1, 0.9, 0.2],
           },
       ),
       models.PointStruct(
           id=2,
           vector={
               "image": [0.2, 0.1, 0.3, 0.9],
               "text": [0.5, 0.2, 0.7, 0.4, 0.7, 0.2, 0.3, 0.9],
           },
       ),
   ],
)
```

## Vector Dimensionality

Dense vectors are the most common type used in semantic search and machine learning applications. Vector dimensionality directly impacts:

- **Search efficiency**
- **Memory consumption**
- **Retrieval accuracy**

**Performance Trade-offs:**

| Dimensions | Speed | Detail | Storage |
|------------|-------|--------|---------|
| 384-512 | Fastest | Lower | Minimal |
| 768-1536 | Balanced | Medium | Moderate |
| 3072+ | Slower | Highest | Heavy |

**Common Model Dimensions:**

| Model | Dimensionality | Use Case |
|-------|----------------|----------|
| MiniLM, MPNet | 384 | Lightweight NLP tasks |
| BERT, Sentence Transformers | 768 | General-purpose embeddings |
| OpenAI text-embedding-3-small | 1536 | High-quality semantic search |
| OpenAI text-embedding-3-large | 3072 | Large-scale RAG |

**Memory Requirements:**
- 1536-dimension Float32 vector = 6KB
- 1M vectors Ã— 6KB = 6GB memory
- 3072-dimension vectors double the requirement

## Common Embedding Sources

### FastEmbed (Qdrant)
**Best for:** On-premise, high-speed embedding generation with minimal dependencies

**Key Features:**
- Optimized for CPU with ONNX Runtime
- Up to 50% faster than PyTorch-based models
- Lightweight: ~67MB vs 300MB+ for Hugging Face models
- Integrated with Qdrant Python client

```python
from qdrant_client import QdrantClient
from qdrant_client.fastembed.text import TextEmbedding

client = QdrantClient("localhost")
embedding_model = TextEmbedding()
vector = embedding_model("Qdrant is a vector database")
```

**When to Choose FastEmbed:**
- On-premise requirements for privacy
- High-speed CPU inference without GPU dependencies
- Tight Qdrant integration
- Scalable, low-cost embedding generation

### OpenAI's text-embedding-3
**Best for:** Cloud-based, high-quality embeddings for general-purpose NLP

**Specifications:**
- Small model: 1536 dimensions (configurable 256-1536)
- Large model: 3072 dimensions (configurable 256-3072)
- Cloud-based with API latency (~50-200ms)
- $0.00002 per 1k tokens (v3-small)

```python
import openai

embedding = openai.Embedding.create(
    input="Qdrant is a vector database",
    model="text-embedding-3"
)
```

**When to Choose OpenAI:**
- Prioritize ease of use and cloud scalability
- Need multilingual support and state-of-the-art accuracy
- Elastic workload with fluctuating demands
- Acceptable API costs and latency

### Hugging Face Sentence Transformers
**Best for:** Flexible, fine-tuned, open-source embeddings for specialized applications

**Features:**
- Wide model selection (MiniLM, MPNet, E5-large)
- Fine-tunable for domain-specific tasks
- Local execution on CPU/GPU
- Dimensions typically 384-1024

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("all-MiniLM-L6-v2")
embedding = model.encode("Qdrant is a powerful vector database")
```

**When to Choose Sentence Transformers:**
- Need domain-specific models (legal, medical, finance)
- Want full control over model selection and fine-tuning
- Have GPU resources for larger models
- On-premise execution with custom accuracy requirements

## Comparison Summary

| Feature | FastEmbed | OpenAI text-embedding-3 | Hugging Face |
|---------|-----------|-------------------------|--------------|
| **Execution** | On-premise (CPU) | Cloud API | Local (CPU/GPU) |
| **Speed** | Fastest on CPU | Slowest (API latency) | Varies by hardware |
| **Accuracy** | High (384-D) | Highest (1536-3072-D) | Varies by model |
| **Best for** | Qdrant-native, fast, lightweight | Cloud-first, high accuracy | Domain-specific, customizable |

## Payloads (Metadata)

While vectors capture the essence of data, **payloads** hold structured metadata for filtering and refinement.

Payloads can store:
- Textual data (descriptions, tags, categories)
- Numerical values (dates, prices, ratings)
- Complex structures (nested objects, arrays)

**Example Use Case:**
When searching for dog images, the vector finds visually similar images, but payload filters can narrow results to:
- Images taken within the last year
- Images tagged with "vacation"
- Images with specific ratings or categories

### Payload Types

| Type | Description | Example |
|------|-------------|---------|
| **Scalar** | Numbers, booleans | `price: 19.99`, `in_stock: true` |
| **Categorical** | Text tags | `category: "electronics"` |
| **Geolocation** | Lat/lon coordinates | `location: {lat: 40.7128, lon: -74.0060}` |
| **Timestamps** | ISO 8601 dates | `created_at: "2024-03-10T12:00:00Z"` |
| **Arrays** | Multiple values | `tags: ["vegan", "organic"]` |
| **Nested Objects** | JSON structures | `user: {"id": 123, "name": "Alice"}` |

### Filtering Options

| Filter Type | Description | Example Query |
|-------------|-------------|---------------|
| **Match** | Exact value | `"match": {"value": "electronics"}` |
| **Match Any** | OR condition | `"match": {"any": ["red", "blue"]}` |
| **Match Except** | NOT IN condition | `"match": {"except": ["banned"]}` |
| **Range** | Numerical ranges | `"range": {"gte": 50, "lte": 200}` |
| **Datetime Range** | Time-based filtering | `"range": {"gt": "2023-01-01T00:00:00Z"}` |
| **Full Text** | Substring matching | `"match": {"text": "amazing service"}` |
| **Geospatial** | Location-based | `"geo_radius": {"center": {...}, "radius": 10000}` |
| **Has ID** | Specific IDs | `"has_id": [1, 5, 10]` |
| **Is Empty** | Missing fields | `"is_empty": {"key": "discount"}` |

## Key Takeaways

1. **Points** are Qdrant's core entity: ID + Vector + Payload
2. **Multiple vector types** support different use cases: dense, sparse, multivector
3. **Named vectors** allow multiple vector spaces per point
4. **Dimensionality choice** balances accuracy, speed, and storage
5. **Embedding sources** offer different trade-offs for speed, accuracy, and deployment
6. **Payloads enable filtering** and structured metadata alongside vector search

Understanding these fundamentals prepares you for building sophisticated search applications with Qdrant's flexible data model. 