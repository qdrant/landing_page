---
title: Points, Vectors, and Payloads
weight: 1
---

{{< date >}} Day 1 {{< /date >}}

# Points, Vectors, and Payloads

Understanding Qdrant's core data model is essential for building effective vector search applications. This lesson establishes the precise technical vocabulary and concepts you'll use throughout the course.

{{< youtube "YOUR_YOUTUBE_VIDEO_ID_HERE" >}}

## Points: The Core Entity

Points are the central entity that Qdrant operates with. A point is a record consisting of three components:

- **Unique ID** (64-bit unsigned integer or UUID)
- **Vector** (dense, sparse, or multivector)
- **Optional Payload** (metadata)

<img src="/courses/day1//point-2.png" alt="Creating an embedding" width="700">

If IDs are not provided, Qdrant Client will automatically generate them as random UUIDs.

## Vector Types in Qdrant

Qdrant supports different types of vectors to provide various approaches to data exploration and search.

### Dense Vectors

At the core of every vector is a set of numbers, which together form a representation of the data in a multi-dimensional space.

Dense vectors are the typical vector representation used in vector search, generated by the majority of the embedding models, and capture the essential patterns or relationships within the data. Thatâ€™s why the term embedding is often used interchangeably with vector when referring to the output of these models.

Embeddings are generated by neural networks to capture complex relationships and semantics within your data. These embeddings are represented as vectors in a high-dimensional space, which can then be stored and searched efficiently in a vector database.

![Embedding generation overview](/courses/day1/embedding-arc.png)

To represent textual data, for example, an embedding will encapsulate the nuances of language, such as semantics and context within its dimensions.

<img src="/courses/day1/vector-data.png" alt="Creating an embedding" width="600">

For that reason, when comparing two similar sentences, their embeddings will turn out to be very similar, because they have similar linguistic elements.

<img src="/courses/day1/embeddings.png" alt="Similar embeddings" width="600">

### Sparse Vectors

Mathematically identical to dense vectors, but containing many zeros. They use optimized storage representation and have a different shape than dense vectors.

**Representation:**
Sparse vectors are represented as a list of (index, value) pairs:
- **index**: integer position of non-zero value
- **value**: floating point number

**Example:**
```python
# Dense vector: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0]
# Sparse representation: [(6, 1.0), (7, 2.0)]

# Qdrant JSON format:
{
 "indices": [6, 7],
 "values": [1.0, 2.0]
}
```

**Implementation:**
```python
client.upsert(
   collection_name="{collection_name}",
   points=[
       models.PointStruct(
           id=1,
           vector={
               "text": models.SparseVector(
                   indices=[6, 7],
                   values=[1.0, 2.0],
               )
           },
       ),
       models.PointStruct(
           id=2,
           vector={
               "text": models.SparseVector(
                   indices=[1, 2, 3, 4, 5],
                   values=[0.1, 0.2, 0.3, 0.4, 0.5],
               )
           },
       ),
   ],
)
```

<img src="/courses/day1/sparse-vector.png" alt="Sparse Vector generation">

The indices and values arrays must have the same length. And the indices must be unique. If the indices are not sorted, Qdrant will sort them internally so you may not rely on the order of the elements.

Sparse vectors **must be named** and can be uploaded in the same way as dense vectors.


### Multivectors

Qdrant supports the storing of a variable amount of same-shaped dense vectors in a single point. This means that instead of a single dense vector, you can upload a matrix of dense vectors.

<img src="/courses/day1/multivector.png" alt="MultivVector generation" width="700">

**Structure:**
- Fixed matrix length per collection
- Variable number of vectors per point
- All vectors in the matrix have the same shape

**Example:**

A multivector of size 4:
```python
"vector": [
   [-0.013,  0.020, -0.007, -0.111],
   [-0.030, -0.055,  0.001,  0.072],
   [-0.041,  0.014, -0.032, -0.062],
   # ...
]
```

**Use Cases:**
- Multiple embeddings for the same object from different angles, same payload
- ColBERT-style models that output vectors for each token
- Any scenario requiring multiple related vectors per data point

So these are the 3 types of vectors we can have and it is possible to attach more than one type of vector to a single point. 

In Qdrant we call these **Named Vectors**.


### Named Vectors

To store different vectors for each point, you need to create separate named vector spaces in the collection. You can define these vector spaces during collection creation and manage them independently.

To create a collection with named vectors, you need to specify a configuration for each vector:

**Collection Creation:**
```python
from qdrant_client import QdrantClient, models

client = QdrantClient(
    "https://your-cluster-url.cloud.qdrant.io", 
    api_key=userdata.get('api-key') 
)

client.create_collection(
   collection_name="{collection_name}",
   vectors_config={
       "image": models.VectorParams(size=4, distance=models.Distance.DOT),
       "text": models.VectorParams(size=5, distance=models.Distance.COSINE),
   },
   sparse_vectors_config={"text-sparse": models.SparseVectorParams()},
)
```

**Point Insertion:**
```python
client.upsert(
   collection_name="{collection_name}",
   points=[
       models.PointStruct(
           id=1,
           vector={
               "image": [0.9, 0.1, 0.1, 0.2],
               "text": [0.4, 0.7, 0.1, 0.8, 0.1, 0.1, 0.9, 0.2],
           },
       ),
       models.PointStruct(
           id=2,
           vector={
               "image": [0.2, 0.1, 0.3, 0.9],
               "text": [0.5, 0.2, 0.7, 0.4, 0.7, 0.2, 0.3, 0.9],
           },
       ),
   ],
)
```

## Vector Dimensionality

Dense vectors are the most common type used in semantic search and machine learning applications. Vector dimensionality directly impacts search efficiency, memory consumption, and retrieval accuracy.

Higher dimensions capture more detail but cost more in storage and compute. The choice balances accuracy against performance: smaller dimensions (384-512) are fastest but less detailed; mid-range (768-1536) offer balanced accuracy and speed; higher dimensions (3072+) provide maximum detail but require more storage.

**Common Model Dimensions:**

| Model | Dimensionality | Use Case |
|-------|----------------|----------|
| MiniLM, MPNet | 384 | Lightweight NLP tasks |
| BERT, Sentence Transformers | 768 | General-purpose embeddings |
| OpenAI text-embedding-3-small | 1536 | High-quality semantic search |
| OpenAI text-embedding-3-large | 3072 | Large-scale RAG |

**Memory impact**: A 1536-dimension Float32 vector requires 6KB. Scale that to 1M vectors and you need 6GB of memory. 3072-dimension vectors double the requirement.

## Common Embedding Sources

### FastEmbed by Qdrant

[FastEmbed](https://github.com/qdrant/fastembed) is Qdrant's optimized embedding solution designed for on-premise, high-speed generation with minimal dependencies. It delivers low-latency, CPU-friendly embedding generation using quantized model weights and ONNX Runtime, making it up to 50% faster than traditional PyTorch-based models while maintaining competitive accuracy.

The default model is lightweight at ~67MB compared to 300MB+ for many Hugging Face models. FastEmbed integrates directly with Qdrant's Python client, reducing code complexity and eliminating the need for separate embedding infrastructure.

```python
from qdrant_client import QdrantClient
from qdrant_client.fastembed.text import TextEmbedding

client = QdrantClient(
    url="https://your-cluster-url.cloud.qdrant.io",
    api_key="your-api-key",
)
embedding_model = TextEmbedding()
vector = embedding_model("Qdrant is a vector database")
```

Choose FastEmbed when you need on-premise execution for privacy-sensitive applications, want high-speed CPU inference without GPU dependencies, require tight Qdrant integration, or need scalable, low-cost embedding generation.

Learn more: [FastEmbed Documentation](https://qdrant.github.io/fastembed/)

### Cloud-based Providers

Commercial embedding APIs from providers like [OpenAI](https://platform.openai.com/docs/guides/embeddings), [Anthropic](https://docs.anthropic.com/), and others offer state-of-the-art embeddings optimized for broad NLP applications with multilingual support. These models typically provide the highest quality embeddings with minimal setup requirements.

Cloud providers generally offer configurable dimensions (e.g., 256-3072) and handle infrastructure scaling automatically. The trade-off is API latency (~50-200ms per request) and usage-based costs, but you eliminate local compute requirements and model management complexity.

```python
# Example with OpenAI (similar patterns for other providers)
import openai

embedding = openai.Embedding.create(
    input="Qdrant is a vector database",
    model="text-embedding-3-small"
)
```

Choose cloud providers when you prioritize ease of use and scalability without model management, need multilingual support or cutting-edge accuracy with minimal setup, can accept API costs and latency for high-quality embeddings, or have fluctuating workloads requiring elastic solutions.

### Open Source Models

[Sentence Transformers](https://www.sbert.net/) and other open-source libraries offer diverse model selections trained for different domains, languages, and tasks. They enable fine-tuning on domain-specific data, making them excellent for specialized retrieval applications.

Popular models include MiniLM (fast, 384 dims), MPNet (balanced, 768 dims), and E5-large (1024 dims, high accuracy). These models run locally on CPU or GPU but require managing dependencies like PyTorch. While non-optimized models are slower than FastEmbed on CPU, they offer extensive customization options.

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("all-MiniLM-L6-v2")
embedding = model.encode("Qdrant is a powerful vector database")
```

Choose open-source models when you need specialized models for specific industries (legal, medical, finance), want full control over model selection and fine-tuning, have GPU resources for larger models, or require on-premise execution with custom accuracy requirements.

Explore models: [Hugging Face Model Hub](https://huggingface.co/models?pipeline_tag=sentence-similarity)

## Embedding Comparison

| Feature | FastEmbed | Cloud Providers | Open Source |
|---------|-----------|-----------------|-------------|
| **Execution** | On-premise (CPU) | Cloud API | Local (CPU/GPU) |
| **Speed** | Fastest on CPU | API latency | Varies by hardware |
| **Accuracy** | High (384-D) | Highest (configurable) | Varies by model |
| **Best for** | Qdrant-native, lightweight | Cloud-first, high accuracy | Domain-specific, customizable |

## Payloads (Metadata)

While vectors capture the essence of data, payloads hold structured metadata for filtering and refinement. This combination enables hybrid search that leverages both semantic similarity and business logic.

Payloads can store textual data (descriptions, tags, categories), numerical values (dates, prices, ratings), and complex structures (nested objects, arrays). When searching for dog images, for example, the vector finds visually similar images while payload filters narrow results to images taken within the last year, tagged with "vacation," or meeting specific rating criteria.

Learn more: [Payload Documentation](https://qdrant.tech/documentation/concepts/payload/)

### Payload Types

Qdrant supports rich metadata structures that enable sophisticated filtering alongside vector search:

| Type | Description | Example |
|------|-------------|---------|
| **Scalar** | Numbers, booleans | `price: 19.99`, `in_stock: true` |
| **Categorical** | Text tags | `category: "electronics"` |
| **Geolocation** | Lat/lon coordinates | `location: {lat: 40.7128, lon: -74.0060}` |
| **Timestamps** | ISO 8601 dates | `created_at: "2024-03-10T12:00:00Z"` |
| **Arrays** | Multiple values | `tags: ["vegan", "organic"]` |
| **Nested Objects** | JSON structures | `user: {"id": 123, "name": "Alice"}` |

### Filtering Logic: Building Complex Queries

Qdrant's filtering system uses logical clauses that can be recursively nested to create sophisticated query logic. Think of these as the building blocks for expressing complex business requirements.

**Logical Clauses:**
- **must**: All conditions must be satisfied (AND logic)
- **should**: At least one condition must be satisfied (OR logic)  
- **must_not**: None of the conditions should be satisfied (NOT logic)

These clauses combine to express complex requirements. For instance, finding "electronics under $200 OR books with 4+ star ratings" becomes:

```python
models.Filter(
    should=[
        models.Filter(must=[
            models.FieldCondition(key="category", match=models.MatchValue(value="electronics")),
            models.FieldCondition(key="price", range=models.Range(lte=200))
        ]),
        models.Filter(must=[
            models.FieldCondition(key="category", match=models.MatchValue(value="books")),
            models.FieldCondition(key="rating", range=models.Range(gte=4.0))
        ])
    ]
)
```

### Condition Types: Precise Control

Beyond basic exact matches, Qdrant provides nuanced condition types for different data scenarios:

**Match Conditions:**
- **Match**: Exact value matching for keywords, numbers, and booleans
- **Match Any**: OR logic across multiple values (equivalent to SQL's IN operator)
- **Match Except**: Exclusion logic (equivalent to SQL's NOT IN operator)

**Range Conditions:**
- **Range**: Numerical boundaries with `gt`, `gte`, `lt`, `lte` operators
- **Datetime Range**: Time-based filtering using RFC 3339 timestamps

**Specialized Conditions:**
- **Geospatial**: Location-based filtering with radius, bounding box, or polygon queries
- **Full Text**: Substring matching within text fields
- **Nested**: Query within arrays of objects, ensuring conditions apply to the same array element
- **Has ID**: Filter by specific point IDs
- **Is Empty/Is Null**: Handle missing or null values
- **Values Count**: Filter based on array length

### Filtering Capabilities Reference

| Filter Type | Description | Example Query |
|-------------|-------------|---------------|
| **Match** | Exact value | `"match": {"value": "electronics"}` |
| **Match Any** | OR condition | `"match": {"any": ["red", "blue"]}` |
| **Match Except** | NOT IN condition | `"match": {"except": ["banned"]}` |
| **Range** | Numerical ranges | `"range": {"gte": 50, "lte": 200}` |
| **Datetime Range** | Time-based filtering | `"range": {"gt": "2023-01-01T00:00:00Z"}` |
| **Full Text** | Substring matching | `"match": {"text": "amazing service"}` |
| **Geospatial** | Location-based | `"geo_radius": {"center": {...}, "radius": 10000}` |
| **Nested** | Array object filtering | `"nested": {"key": "reviews", "filter": {...}}` |
| **Has ID** | Specific IDs | `"has_id": [1, 5, 10]` |
| **Is Empty** | Missing fields | `"is_empty": {"key": "discount"}` |
| **Is Null** | Null values | `"is_null": {"key": "field"}` |
| **Values Count** | Array length | `"values_count": {"gt": 2}` |

### Advanced Filtering: Nested Objects

For complex data structures like arrays of objects, Qdrant provides nested filtering that ensures conditions are evaluated within individual array elements rather than across all elements.

Consider a product with multiple reviews:
```json
{
  "id": 1,
  "product": "Laptop",
  "reviews": [
    {"user": "alice", "rating": 5, "verified": true},
    {"user": "bob", "rating": 3, "verified": false}
  ]
}
```

To find products with verified 5-star reviews (both conditions must apply to the same review):

```python
models.Filter(
    must=[
        models.NestedCondition(
            nested=models.Nested(
                key="reviews",
                filter=models.Filter(must=[
                    models.FieldCondition(key="rating", match=models.MatchValue(value=5)),
                    models.FieldCondition(key="verified", match=models.MatchValue(value=True))
                ])
            )
        )
    ]
)
```

Without nested filtering, Qdrant would match products where ANY review has a 5-star rating AND ANY review is verified - potentially different reviews.

### Performance Optimization

To maximize filtering performance, create payload indexes for frequently filtered fields. Qdrant automatically optimizes query execution based on filter cardinality and available indexes.

```python
# Index frequently filtered fields
client.create_payload_index(
    collection_name="products",
    field_name="category",
    field_schema=models.PayloadSchemaType.KEYWORD
)

# For multi-tenant applications, mark tenant fields
client.create_payload_index(
    collection_name="products", 
    field_name="tenant_id",
    field_schema=models.KeywordIndexParams(type="keyword", is_tenant=True)
)
```

When filters are highly selective, Qdrant's query planner may bypass vector indexing entirely and use payload indexes for faster results.

For comprehensive filtering examples and advanced usage patterns, see the [Filtering Documentation](https://qdrant.tech/documentation/concepts/filtering/) and [Complete Guide to Filtering in Vector Search](https://qdrant.tech/articles/vector-search-filtering/).

## Key Takeaways

Understanding Qdrant's data model prepares you for building sophisticated search applications. Points combine unique IDs, vectors, and metadata into a flexible foundation. Multiple vector types (dense, sparse, multivector) support different use cases, while named vectors enable multiple vector spaces per point. Dimensionality choice balances accuracy against performance, and various embedding sources offer different trade-offs for speed, accuracy, and deployment requirements. Finally, payloads enable rich filtering and structured metadata alongside vector search.

This foundation sets you up for the advanced topics ahead: distance metrics, chunking strategies, and building real-world search systems. 