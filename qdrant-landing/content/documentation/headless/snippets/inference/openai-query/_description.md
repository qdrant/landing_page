This code snippet illustrates how to use the OpenAI API for query-time inference on Qdrant Cloud. Instead of supplying an explicit query vector, the query provides text, along with the name of an OpenAI model. When the model name is prepended with `openai/`, the Qdrant Cloud Inference proxy uses the OpenAI API to infer embeddings out of the provided text. Qdrant will search with the resulting vector. The request also shows how to pass OpenAI-specific parameters to the API. In this case, the request provides the OpenAI API key and the `dimensions` parameter.