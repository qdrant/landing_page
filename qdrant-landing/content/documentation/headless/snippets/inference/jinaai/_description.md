This code snippet demonstrates how to use the Jina AI API for inference on Qdrant Cloud. The example first creates a collection that supports vectors with 512 dimensions. Next, a point is inserted, but instead of providing an explicit vector, the example request includes text along with the name of an Jina AI model. When the model name is prepended with `jinaai/`, the Qdrant Cloud Inference proxy will use the Jina AI API to infer embeddings out of the provided text and store the resulting vector. The request also shows how to pass Jina AI-specific parameters to the API. In this case, the request passes the Jina AI API key and the `dimensions` parameter. Finally, the example shows how to use the Jina AI API for query-time inference. Instead of supplying an explicit query vector, the query includes text and name of an Jina AI model, as well as an Jina AI API key and the Jina AI-specific `dimensions` parameter. When the model name is prepended with `jinaai/`, the Qdrant Cloud Inference proxy will use the Jina AI API to infer embeddings out of the provided text and search with the resulting vector.