---
draft: false
title: Hybrid Search in Qdrant
slug: hybrid-search-in-Qdrant
short_description: How to Combine Dense and Sparse Vectors for Superior Results
description: In this blog, we will cover everything you need to know when building a hybrid search application while leveraging the power of Qdrant..
preview_image: /blog/Hybrid-Search-in-Qdrant/preview.png
date: 2025-06-23T16:40:55.469Z
author: Derrick Mwiti
featured: false
tags:
  - Hybrid serch
  - dense vectors
  - sparse vectors
  - fusion strategies
---
# Hybrid Search in Qdrant

## How to Combine Dense and Sparse Vectors for Superior Results

Hybrid search has become a key technique in combining the strengths of keyword-based and vector-based search. A pure keyword-based or vector-based search often falls short due to growing datasets and the ever-increasing complexity of semantic search. Enter hybrid search. 

In this blog, we will cover everything you need to know when building a hybrid search application while leveraging the power of Qdrant. Whether you are building a semantic product search, a personalized recommendation system, or a chatbot, hybrid search can improve retrieval quality drastically.  Specifically, we’ll cover:

* What is hybrid search?  
* The motivation behind it.  
* How Qdrant supports multiple hybrid search modes. 

Let’s start by defining what hybrid search means.

## What is Hybrid Search?

Hybrid search involves combining two fundamental retrieval methods: 

* **Sparse search (e.g., BM25)** that focuses on partial or exact matches between queries and indexed documents.   
* **Dense search** that captures meaning and context learned from embeddings generated by models such as BERT and OpenAI embedding models. 

Combining the two approaches leads to increased recall and precision in retrieval. In practice, this can involve:

* Searching both a TF-IDF and a vector.   
* Combining the results through weighting or reranking.   
* Using the same database to index sparse and dense vectors.

As you will discover below, Qdrant supports hybrid search with integration models for different use cases. 

## Qdrant Hybrid Search Modes

Qdrant supports hybrid search as a first-class feature by providing ways to merge results from sparse and dense vectors. Let’s walk through the main hybrid models that Qdrant supports.

### Late fusion (reranking)

In Qdrant, late fusion involves running separate sparse and dense queries, merging their results, and reranking them to find the top results. 

In practice, this involves: 

* Creating a sparse vector using something like BM25.   
* Creating a dense vector using Sentence Transformers or OpenAI models.   
* Combining the results and using built-in methods such as Reciprocal Rank Fusion (RRF) or Distance-Based Score Fusion (DBSF) to rank the results.   
* Reranking the results using late interaction models such as ColBert. 

### Linear fusion (score blending)

Qdrant supports the inclusion of both named dense and sparse vectors, leading to blended vectors across modalities. Qdrant’s Hybrid Query API supports specifying weights in the query body. This lets you control how dense and sparse signals affect the final results. 

### Multi-vector payloads

A single vector might not be enough to capture the whole meaning of a document. To fix this, we can use multi-vector payloads from Qdrant to store multiple vectors per item. This means that instead of compressing all the information into one vector, you can split it into different vectors using named vectors.  For example:

```json
{

  "id": "doc_001",

  "payload": {

    "title": "Introduction to Reinforcement Learning",

    "body": "This paper explores Markov Decision Processes...",

    "tags": ["AI", "RL", "learning"]

  },

  "vectors": {

    "title_vector": [...],

    "body_vector": [...],

    "tags_vector": [...]

  }

}
```
This will allow you to query the sub-vectors independently or combine them during search. Multivector payloads help capture context from different document parts, such as the title and body, enabling you to match queries more accurately to specific document parts.  Multivectors also allow for multimodal data such as images and text. For example, you can set up a query that targets: 

* A single vector, such as the title vector only.   
* Multiple vectors with weights for each, e.g, 0.7 for title and 0.3 for body. 

### Advanced Options

While Qdrant’s built-in modes cover most scenarios, you might encounter situations that demand custom logic. Fortunately, Qdrant doesn’t limit you to just the models we have covered. Qdrant supports advanced options such as: 

* **Custom scoring functions** that allow you to define your custom logic. For example, business logic to boost recent documents or premium items.  
* **Payload filtering combined with hybrid search** enables you to limit the results to a specific category. For example, in a medical chatbot, you can filter the results through a particular specialty and medical literature within a specific year range.    
* **External rerankers and LLMs** to enable you to use different rerankers such as OpenAI, Cohere, or LLM-based scoring.   
 


## Designing Your Hybrid Payload

To get the most out of hybrid search in Qdrant, structure your dense and sparse vectors to support meaningful and efficient retrieval. A typical hybrid payload includes:

* **Dense vectors**: Embeddings for your content.   
* **Sparse vectors**: Tokenized or TF-IDF/Bag-of-Words representations, stored as indexed keyword maps.  
* **Metadata**: Filters or labels such as language, timestamp, and category.  
* **Named vector fields**: To enable targeted or multi-vector retrieval.

### Structuring both dense and sparse vectors

Dense vectors are usually created using embedding models such as: 

* OpenAI  
* Sentence Traansformers  
* Cohere  
* Custom domain-tuned models 

Sparse vectors can be generated using TF-IDF or BM25. 

Here are some things to consider when creating these embedding vectors:

* Use domain-specific models. For example, instead of general models for a medical use case, you can use a model already trained on medical data.   
* Chunk long documents. Consider breaking up large text into sections and embedding them separately.   
* Name your vector fields appropriately for targeted queries. 

### Example schemas

For hybrid search to work in Qdrant, you must define a schema that supports sparse and dense vectors. Here are a few examples based on everyday use cases. 

Simple document search:

```python
from qdrant_client import QdrantClient, models

client = QdrantClient("http://localhost:6333")  # or your Qdrant endpoint

client.upload_points(  
    collection_name="my-collection",  
    points=[  
        models.PointStruct(  
            id="doc_001",  
            payload={  
                "title": "Resetting Your Router",  
                "body": "If your internet connection drops...",  
                "category": "support"  
            },  
            vectors={  
                "dense": [...],  # your dense embedding here  
                "late-interaction": [[...], [...], [...]]  # list of sub-vectors for multivector  
            },  
            sparse_vectors={  
                "sparse": models.SparseVector(  
                    indices=[12, 104, 304],  
                    values=[0.8, 0.6, 0.3]  
                )  
            }  
        )  
    ]  
)
```
E-commerce product search:

```python
from qdrant_client import QdrantClient, models

client = QdrantClient("http://localhost:6333")  # or your Qdrant endpoint

client.upload_points(  
    collection_name="ecommerce-products",  
    points=[  
        models.PointStruct(  
            id="product_12345",  
            payload={  
                "product_name": "Wireless Noise-Canceling Headphones",  
                "description": "Experience high-quality audio with active noise cancellation and 30-hour battery life.",  
                "category": "electronics",  
                "brand": "SoundMax",  
                "price": 149.99,  
                "in_stock": True  
            },  
            vectors={  
                "dense": [  
                    0.12, 0.08, -0.03, 0.17,  # ← example 4D embedding for demo  
                    0.26, -0.11, 0.05, 0.31  
                ],  
                "late-interaction": [  
                    [0.01, 0.12, 0.07, 0.05],  
                    [-0.06, 0.08, 0.09, 0.02],  
                    [0.03, 0.00, -0.02, 0.04]  
                ]  
            },  
            sparse_vectors={  
                "sparse": models.SparseVector(  
                    indices=[21, 104, 230, 305],  
                    values=[0.9, 0.75, 0.6, 0.4]  
                )  
            }  
        )  
    ]  
)
```

The schemas illustrate how hybrid-ready documents are structured, with dense vectors for meaning, sparse maps for precision, and payload metadata for filtering. 

## Best practices for efficient search

Observe the following best practices to optimize for speed and relevance: 

* Use smaller dimensions, such as 256 and 384, to reduce memory usage and speed up similarity calculations, unless large dimensions are necessary.   
* Normalize dense vectors before indexing to ensure consistent similarity scoring.   
* Preprocess sparse tokens by removing stopwords while using a consistent token to reduce variability across documents and queries.  
* Use targeted named vectors instead of embedding everything into a single vector to improve match quality and interpretability.   
* Cache frequent queries to avoid redundant scoring and improve response time for high-traffic endpoints.  
* Batch queries when handling multiple user queries to reduce I/O overhead. 

## Fusion Strategies

Hybrid search is powerful, but its performance is determined by combining the scores from the dense and sparse vectors. Qdrant provides various ways to blend these scores. 

Let’s explore the key approaches.

### Score blending with weights

Score blending is one of the most intuitive approaches in hybrid fusion. The objective is to combine keyword-based and semantic signals into a single score. This can be conceptually expressed as:
```markdown
final_score = α * dense_score + (1 - α) * sparse_score
```
In the formula, dense score is the similarity between the query and the dense vector, while the sparse score is obtained from methods such as BM25 or TF-IDF. This can be achieved in Qdrant by using the dense and sparse vectors while using `prefetch` to retrieve both sets and apply fusion strategies. RRF gives a balanced rank boost to documents appearing in both lists, while DBSF normalizes score blending across query types.

### Score normalization

Combining scores from dense and sparse vectors involves mixing apples and oranges. That is, similarity scores from the dense vector and BM25 scores. Since these can be unbounded and skewed, normalization brings them under a standard scale. This ensures that a single score type doesn’t dominate. Some common ways to normalize scores before fusion include: 

* Min-Max Scaling 
```markdown
normalized_score = (score - min) / (max - min)
```

* Z-Score Normalization

```markdown
z = (score - mean) / std
```
* Softmax Scaling

```markdown
normalized_score = exp(score) / Σ exp(all_scores)
```
### Reranking with external logic

Reranking with external logic gives you more control over the final ordering of the search results. For example, incorporating domain knowledge, user behaviour, or machine learning. This can be done with the following steps: 

* Perform initial retrieval to fetch a broad set of candidates, such as the top 100 results.   
* Apply custom logic for reranking using machine learning or external APIs such as Cohere Rerank or other reranking models.   
* Return the top-k reranked items to the user. 

Reranking can lead to better results, but not without some tradeoffs, such as: 

* The need for extra infrastructure or model hosting.   
* Increased latency when using external APIs.   
* The need for labeled data if you will train rerankers. 

## Performance Considerations

With hybrid search, you must consider trade-offs in three critical areas described below. 

### Indexing cost

Vector indexing for large vectors or multi-vector payloads is more computationally and memory-intensive than sparse indexing. You can reduce the overhead by uploading the data in batches and using `ON\_DISK` storage for large collections when RAM is constrained. These options are natively supported in Qdrant. 

### Query latency

Dense vector similarity search is more expensive than sparse term matching. Hybrid queries combine both; therefore, the response time will be slightly higher than for a single method. Latency is also dictated by:

* Vector dimension   
* Number of vectors per item  
* Top-k results required   
* Payload filters.

Payload filters can improve speed by shrinking the search space. Reranking using a small candidate set can also improve search speed. 

### Memory and scaling

Dense vectors are more memory-heavy. Sparse tokens scale better, but with a large dataset, that can still add up. On the other hand, multi-vector indexing also requires more storage. Monitor the collection size and memory storage to stay on top of things. Consider applying compression techniques such as quantization if the precision trade-off is acceptable. 

## Conclusion

Hybrid search is a practical solution for balancing exactness with meaning. By combining sparse and dense retrieval methods, you can capture the precision of keyword matching and the depth of semantic understanding. Applying these techniques with Qdrant doesn’t require bespoke engineering, but it’s built-in and production-ready. Try it today on [Qdrant Cloud](https://qdrant.tech/cloud/). 